"""
LightGBM ã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬
ã€œãƒ©ã‚°ç‰¹å¾´é‡ã§éå»ã‹ã‚‰æœªæ¥ã‚’å­¦ã¶ã€œ

âš ï¸ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼š
æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§GBDTã‚’ä½¿ã†å ´åˆã€ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã«ç´°å¿ƒã®æ³¨æ„ãŒå¿…è¦ï¼
æœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦éå»ã‚’äºˆæ¸¬ã—ãªã„ã‚ˆã†ã«ã—ã‚ˆã†
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import lightgbm as lgb
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from typing import Tuple, Dict, List
import warnings
import japanize_matplotlib

warnings.filterwarnings('ignore')


def mean_absolute_percentage_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """MAPEï¼ˆå¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®ï¼‰ã‚’è¨ˆç®—"""
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mask = y_true != 0
    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100


def create_lag_features(
    df: pd.DataFrame,
    target_col: str = 'sales',
    lag_days: List[int] = None
) -> pd.DataFrame:
    """
    ãƒ©ã‚°ç‰¹å¾´é‡ã‚’ä½œæˆ

    âš ï¸ ãƒã‚¤ãƒ³ãƒˆï¼šäºˆæ¸¬æ™‚ç‚¹ã§ä½¿ãˆã‚‹ãƒ©ã‚°ã ã‘ã‚’ä½¿ã†
    ä¾‹ãˆã°ã€ç¿Œæ—¥ã‚’äºˆæ¸¬ã™ã‚‹å ´åˆã¯lag=1ï¼ˆå‰æ—¥ã®å€¤ï¼‰ã¯ä½¿ãˆã‚‹ãŒã€
    lag=0ï¼ˆå½“æ—¥ã®å€¤ï¼‰ã¯ä½¿ãˆãªã„

    Parameters
    ----------
    df : pd.DataFrame
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
    target_col : str
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—å
    lag_days : List[int]
        ãƒ©ã‚°ã®æ—¥æ•°ãƒªã‚¹ãƒˆ

    Returns
    -------
    pd.DataFrame
        ãƒ©ã‚°ç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
    """
    if lag_days is None:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ©ã‚°ï¼ˆ1æ—¥å‰ã‹ã‚‰7æ—¥å‰ã€14æ—¥å‰ã€28æ—¥å‰ï¼‰
        lag_days = [1, 2, 3, 4, 5, 6, 7, 14, 21, 28]

    df = df.copy()

    print(f"ğŸ“Š ãƒ©ã‚°ç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")

    for lag in lag_days:
        df[f'lag_{lag}'] = df[target_col].shift(lag)
        print(f"   - lag_{lag}: {lag}æ—¥å‰ã®å£²ä¸Š")

    return df


def create_rolling_features(
    df: pd.DataFrame,
    target_col: str = 'sales',
    windows: List[int] = None
) -> pd.DataFrame:
    """
    ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç‰¹å¾´é‡ï¼ˆç§»å‹•çµ±è¨ˆé‡ï¼‰ã‚’ä½œæˆ

    âš ï¸ ãƒã‚¤ãƒ³ãƒˆï¼šmin_periods ã‚’ä½¿ã£ã¦NaNã‚’é¿ã‘ã¤ã¤ã€
    shift(1) ã§å½“æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã‚ãªã„ã‚ˆã†ã«ã™ã‚‹

    Parameters
    ----------
    df : pd.DataFrame
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
    target_col : str
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—å
    windows : List[int]
        ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®ãƒªã‚¹ãƒˆ

    Returns
    -------
    pd.DataFrame
        ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
    """
    if windows is None:
        windows = [7, 14, 28]

    df = df.copy()

    print(f"\nğŸ“Š ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")

    for window in windows:
        # shift(1) ã§å½“æ—¥ã‚’é™¤å¤–ã—ã¦ã‹ã‚‰rollingã‚’è¨ˆç®—
        # ã“ã‚Œã‚’å¿˜ã‚Œã‚‹ã¨ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ï¼
        shifted = df[target_col].shift(1)

        df[f'rolling_mean_{window}'] = shifted.rolling(window=window, min_periods=1).mean()
        df[f'rolling_std_{window}'] = shifted.rolling(window=window, min_periods=1).std()
        df[f'rolling_max_{window}'] = shifted.rolling(window=window, min_periods=1).max()
        df[f'rolling_min_{window}'] = shifted.rolling(window=window, min_periods=1).min()

        print(f"   - rolling_{window}: {window}æ—¥é–“ã®çµ±è¨ˆé‡ï¼ˆmean, std, max, minï¼‰")

    return df


def create_date_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ—¥ä»˜ã«åŸºã¥ãç‰¹å¾´é‡ã‚’ä½œæˆ

    ã“ã‚Œã‚‰ã¯æœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã„ãªã„ã®ã§ãƒªãƒ¼ã‚¯ã®å¿ƒé…ãªã—
    """
    df = df.copy()

    print(f"\nğŸ“Š æ—¥ä»˜ç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")

    # åŸºæœ¬çš„ãªæ—¥ä»˜ç‰¹å¾´é‡ï¼ˆæ—¢ã«ã‚ã‚‹ã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    if 'day_of_week' not in df.columns:
        df['day_of_week'] = df['date'].dt.dayofweek
    if 'month' not in df.columns:
        df['month'] = df['date'].dt.month
    if 'day' not in df.columns:
        df['day'] = df['date'].dt.day

    # è¿½åŠ ã®æ—¥ä»˜ç‰¹å¾´é‡
    df['day_of_year'] = df['date'].dt.dayofyear
    df['week_of_year'] = df['date'].dt.isocalendar().week.astype(int)
    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)

    # æœˆã®é€±ï¼ˆæœˆåˆã€æœˆä¸­ã€æœˆæœ«ï¼‰
    df['week_of_month'] = (df['day'] - 1) // 7 + 1

    # å­£ç¯€ï¼ˆæ˜¥å¤ç§‹å†¬ï¼‰
    df['season'] = df['month'].map({
        1: 0, 2: 0, 3: 1, 4: 1, 5: 1, 6: 2,
        7: 2, 8: 2, 9: 3, 10: 3, 11: 3, 12: 0
    })

    # ã‚µã‚¤ãƒ³ãƒ»ã‚³ã‚µã‚¤ãƒ³å¤‰æ›ï¼ˆå‘¨æœŸæ€§ã‚’æ‰ãˆã‚‹ï¼‰
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)

    print("   - day_of_year, week_of_year, week_of_month, season")
    print("   - sin/coså¤‰æ›ï¼ˆæœˆã€æ›œæ—¥ï¼‰")

    return df


def create_event_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    ã‚¤ãƒ™ãƒ³ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆ
    """
    df = df.copy()

    print(f"\nğŸ“Š ã‚¤ãƒ™ãƒ³ãƒˆç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")

    # ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼ˆãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
    if 'event' in df.columns:
        event_dummies = pd.get_dummies(df['event'], prefix='event')
        df = pd.concat([df, event_dummies], axis=1)
        print(f"   - ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–: {list(event_dummies.columns)}")

    return df


def prepare_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    å…¨ã¦ã®ç‰¹å¾´é‡ã‚’æº–å‚™

    âš ï¸ é‡è¦ï¼šãƒ©ã‚°ç‰¹å¾´é‡ä½œæˆå¾Œã€NaNãŒå«ã¾ã‚Œã‚‹æœ€åˆã®è¡Œã¯å‰Šé™¤ãŒå¿…è¦
    """
    print("\n" + "=" * 50)
    print("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
    print("=" * 50)

    df = df.copy()
    df = df.sort_values('date').reset_index(drop=True)

    # å„ç‰¹å¾´é‡ã‚’ä½œæˆ
    df = create_date_features(df)
    df = create_event_features(df)
    df = create_lag_features(df)
    df = create_rolling_features(df)

    # NaNã‚’å«ã‚€è¡Œæ•°ã‚’ç¢ºèª
    nan_rows = df.isnull().any(axis=1).sum()
    print(f"\nâš ï¸ NaNã‚’å«ã‚€è¡Œæ•°: {nan_rows}")

    return df


def train_test_split_timeseries(
    df: pd.DataFrame,
    test_days: int = 60
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ãƒ»ãƒ†ã‚¹ãƒˆã«åˆ†å‰²

    âš ï¸ ãƒã‚¤ãƒ³ãƒˆï¼šæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¯çµ¶å¯¾ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ãªã„ï¼
    æœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ãŒå­¦ç¿’ã«æ··ã˜ã‚‹ã¨å¤§æƒ¨äº‹
    """
    df = df.sort_values('date').reset_index(drop=True)

    split_idx = len(df) - test_days
    train_df = df.iloc[:split_idx].copy()
    test_df = df.iloc[split_idx:].copy()

    return train_df, test_df


def get_feature_columns(df: pd.DataFrame) -> List[str]:
    """
    ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã‚«ãƒ©ãƒ ã‚’å–å¾—

    é™¤å¤–ã™ã‚‹ã‚‚ã®ï¼š
    - dateï¼ˆæ—¥ä»˜å‹ï¼‰
    - salesï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰
    - eventï¼ˆæ–‡å­—åˆ—ã€ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–æ¸ˆã¿ï¼‰
    - ä¸€æ™‚çš„ãªã‚«ãƒ©ãƒ 
    """
    exclude_cols = ['date', 'sales', 'event', 'sales_ma7', 'sales_ma30', 'dow_name']

    feature_cols = [col for col in df.columns if col not in exclude_cols]

    return feature_cols


def train_lightgbm(
    train_df: pd.DataFrame,
    feature_cols: List[str],
    target_col: str = 'sales'
) -> lgb.LGBMRegressor:
    """
    LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’

    Parameters
    ----------
    train_df : pd.DataFrame
        å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
    feature_cols : List[str]
        ç‰¹å¾´é‡ã‚«ãƒ©ãƒ 
    target_col : str
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ©ãƒ 

    Returns
    -------
    lgb.LGBMRegressor
        å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    """
    print("\n" + "=" * 50)
    print("ğŸŒ² LightGBM ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    print("=" * 50)

    # NaNã‚’å‰Šé™¤
    train_clean = train_df.dropna(subset=feature_cols + [target_col])
    print(f"\nå­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(train_clean)} ä»¶ï¼ˆNaNå‰Šé™¤å¾Œï¼‰")

    X_train = train_clean[feature_cols]
    y_train = train_clean[target_col]

    # LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'n_estimators': 500,
        'early_stopping_rounds': 50,
        'verbose': -1,
        'random_state': 42,
    }

    print(f"\nğŸ”§ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    for key, value in list(params.items())[:6]:
        print(f"   - {key}: {value}")

    # ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
    model = lgb.LGBMRegressor(**params)

    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ€å¾Œã®20%ã‚’ä½¿ç”¨
    val_size = int(len(X_train) * 0.2)
    X_train_fit = X_train.iloc[:-val_size]
    y_train_fit = y_train.iloc[:-val_size]
    X_val = X_train.iloc[-val_size:]
    y_val = y_train.iloc[-val_size:]

    model.fit(
        X_train_fit, y_train_fit,
        eval_set=[(X_val, y_val)],
    )

    print(f"\nâœ… å­¦ç¿’å®Œäº†ï¼ãƒ™ã‚¹ãƒˆ iteration: {model.best_iteration_}")

    return model


def evaluate_lightgbm(
    model: lgb.LGBMRegressor,
    test_df: pd.DataFrame,
    feature_cols: List[str],
    target_col: str = 'sales'
) -> Tuple[pd.DataFrame, Dict[str, float]]:
    """
    LightGBMãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
    """
    print("\nğŸ“Š ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ä¸­...")

    # NaNã‚’å‰Šé™¤
    test_clean = test_df.dropna(subset=feature_cols + [target_col])
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_clean)} ä»¶ï¼ˆNaNå‰Šé™¤å¾Œï¼‰")

    X_test = test_clean[feature_cols]
    y_test = test_clean[target_col]

    # äºˆæ¸¬
    y_pred = model.predict(X_test)

    # è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    metrics = {
        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),
        'MAE': mean_absolute_error(y_test, y_pred),
        'MAPE': mean_absolute_percentage_error(y_test, y_pred),
        'R2': r2_score(y_test, y_pred)
    }

    print("\nğŸ“ˆ LightGBM è©•ä¾¡çµæœ:")
    print(f"   RMSE: Â¥{metrics['RMSE']:,.0f}")
    print(f"   MAE:  Â¥{metrics['MAE']:,.0f}")
    print(f"   MAPE: {metrics['MAPE']:.2f}%")
    print(f"   RÂ²:   {metrics['R2']:.4f}")

    # çµæœã‚’DataFrameã«
    results = test_clean[['date', target_col]].copy()
    results['prediction'] = y_pred

    return results, metrics


def plot_feature_importance(
    model: lgb.LGBMRegressor,
    feature_cols: List[str],
    save_path: str = "figures/"
) -> None:
    """ç‰¹å¾´é‡é‡è¦åº¦ã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
    import os
    os.makedirs(save_path, exist_ok=True)

    # ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
    importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=True)

    # ä¸Šä½20ä»¶ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    top_n = 20
    importance_top = importance.tail(top_n)

    fig, ax = plt.subplots(figsize=(10, 8))
    ax.barh(importance_top['feature'], importance_top['importance'], color='steelblue')
    ax.set_title(f'LightGBM ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½{top_n}ï¼‰', fontsize=14, fontweight='bold')
    ax.set_xlabel('é‡è¦åº¦')

    plt.tight_layout()
    plt.savefig(f"{save_path}08_lightgbm_importance.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ… {save_path}08_lightgbm_importance.png ã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def plot_lightgbm_results(
    results: pd.DataFrame,
    save_path: str = "figures/"
) -> None:
    """äºˆæ¸¬çµæœã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
    import os
    os.makedirs(save_path, exist_ok=True)

    fig, ax = plt.subplots(figsize=(14, 6))

    ax.plot(results['date'], results['sales'],
            label='å®Ÿç¸¾', linewidth=2, marker='o', markersize=3)
    ax.plot(results['date'], results['prediction'],
            label='äºˆæ¸¬', linewidth=2, linestyle='--')

    ax.set_title('ãƒ†ã‚¹ãƒˆæœŸé–“: å®Ÿç¸¾ vs äºˆæ¸¬ (LightGBM)', fontsize=14, fontweight='bold')
    ax.set_xlabel('æ—¥ä»˜')
    ax.set_ylabel('å£²ä¸Šï¼ˆå††ï¼‰')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(f"{save_path}09_lightgbm_test_comparison.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ… {save_path}09_lightgbm_test_comparison.png ã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸŒ² LightGBM ã«ã‚ˆã‚‹å£²ä¸Šäºˆæ¸¬")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv("apparel_sales_preprocessed.csv")
    df['date'] = pd.to_datetime(df['date'])

    # ç‰¹å¾´é‡ã‚’æº–å‚™
    df = prepare_features(df)

    # ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã‚’å–å¾—
    feature_cols = get_feature_columns(df)
    print(f"\nğŸ“Š ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡: {len(feature_cols)} å€‹")

    # å­¦ç¿’ãƒ»ãƒ†ã‚¹ãƒˆã«åˆ†å‰²
    train_df, test_df = train_test_split_timeseries(df, test_days=60)
    print(f"\nğŸ“… ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
    print(f"   å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {train_df['date'].min().strftime('%Y-%m-%d')} ã€œ {train_df['date'].max().strftime('%Y-%m-%d')} ({len(train_df)}ä»¶)")
    print(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_df['date'].min().strftime('%Y-%m-%d')} ã€œ {test_df['date'].max().strftime('%Y-%m-%d')} ({len(test_df)}ä»¶)")

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model = train_lightgbm(train_df, feature_cols)

    # è©•ä¾¡
    results, metrics = evaluate_lightgbm(model, test_df, feature_cols)

    # ãƒ—ãƒ­ãƒƒãƒˆ
    plot_feature_importance(model, feature_cols)
    plot_lightgbm_results(results)

    # çµæœã‚’ä¿å­˜
    results.to_csv("lightgbm_predictions.csv", index=False)
    print("\nâœ… äºˆæ¸¬çµæœã‚’ lightgbm_predictions.csv ã«ä¿å­˜ã—ã¾ã—ãŸ")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜
    metrics_df = pd.DataFrame([metrics])
    metrics_df['model'] = 'LightGBM'
    metrics_df.to_csv("lightgbm_metrics.csv", index=False)

    return model, results, metrics


if __name__ == "__main__":
    model, results, metrics = main()
