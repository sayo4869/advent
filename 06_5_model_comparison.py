"""
Prophet vs LightGBM vs Chronos vs Chronos-Bolt å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
ã€œ10ç¨®é¡ã®æ™‚ç³»åˆ—äºˆæ¸¬æ‰‹æ³•ã‚’å¾¹åº•æ¯”è¼ƒã€œ

æ¯”è¼ƒã™ã‚‹ãƒ¢ãƒ‡ãƒ«:
- Prophet: Metaã®æ™‚ç³»åˆ—äºˆæ¸¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆåˆ†è§£å¯èƒ½ã€è§£é‡ˆæ€§é«˜ã„ï¼‰
- LightGBM: å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ï¼ˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é‡è¦ï¼‰
- Chronos-tiny:  8M paramsï¼ˆè»½é‡ã€é«˜é€Ÿï¼‰
- Chronos-small: 46M paramsï¼ˆãƒãƒ©ãƒ³ã‚¹è‰¯ã„ï¼‰
- Chronos-base:  200M paramsï¼ˆé«˜ç²¾åº¦ï¼‰
- Chronos-large: 710M paramsï¼ˆæœ€é«˜ç²¾åº¦ï¼‰
- Bolt-tiny:  9M paramsï¼ˆè¶…é«˜é€Ÿï¼‰
- Bolt-mini:  21M paramsï¼ˆé«˜é€Ÿï¼‰
- Bolt-small: 48M paramsï¼ˆãƒãƒ©ãƒ³ã‚¹è‰¯ã„ï¼‰
- Bolt-base:  205M paramsï¼ˆé«˜ç²¾åº¦ï¼‰
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score
import warnings
import japanize_matplotlib
import os

warnings.filterwarnings('ignore')

# Chronosãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
CHRONOS_SIZES = ["tiny", "small", "base", "large"]

# Chronos-Boltãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
BOLT_SIZES = ["tiny", "mini", "small", "base"]

# ãƒ¢ãƒ‡ãƒ«ã®è‰²è¨­å®š
MODEL_COLORS = {
    'Prophet': '#ff6b6b',
    'LightGBM': '#4dabf7',
    'Chronos-tiny': '#a8e6cf',
    'Chronos-small': '#feca57',
    'Chronos-base': '#48dbfb',
    'Chronos-large': '#5f27cd',
    'Bolt-tiny': '#ff9ff3',
    'Bolt-mini': '#f368e0',
    'Bolt-small': '#ee5a24',
    'Bolt-base': '#c23616'
}


def mean_absolute_percentage_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """MAPEï¼ˆå¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®ï¼‰ã‚’è¨ˆç®—"""
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mask = y_true != 0
    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100


def load_all_predictions() -> dict[str, pd.DataFrame]:
    """å…¨ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœã‚’èª­ã¿è¾¼ã‚€"""
    predictions = {}

    # Prophet
    if os.path.exists("prophet_predictions.csv"):
        print("ğŸ“‚ Prophetäºˆæ¸¬ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        prophet_df = pd.read_csv("prophet_predictions.csv")
        prophet_df['ds'] = pd.to_datetime(prophet_df['ds'])
        prophet_df = prophet_df.rename(columns={'ds': 'date', 'y': 'actual', 'yhat': 'prediction'})
        predictions['Prophet'] = prophet_df
        print(f"   âœ… {len(prophet_df)}ä»¶")
    else:
        print("   âš ï¸ prophet_predictions.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    # LightGBM
    if os.path.exists("lightgbm_predictions.csv"):
        print("ğŸ“‚ LightGBMäºˆæ¸¬ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        lgb_df = pd.read_csv("lightgbm_predictions.csv")
        lgb_df['date'] = pd.to_datetime(lgb_df['date'])
        lgb_df = lgb_df.rename(columns={'sales': 'actual'})
        predictions['LightGBM'] = lgb_df
        print(f"   âœ… {len(lgb_df)}ä»¶")
    else:
        print("   âš ï¸ lightgbm_predictions.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    # Chronosï¼ˆå…¨ã‚µã‚¤ã‚ºï¼‰
    for size in CHRONOS_SIZES:
        filename = f"chronos_predictions_{size}.csv"
        print(f"ğŸ“‚ Chronos-{size}äºˆæ¸¬ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        if os.path.exists(filename):
            chronos_df = pd.read_csv(filename)
            chronos_df['date'] = pd.to_datetime(chronos_df['date'])
            chronos_df = chronos_df.rename(columns={'sales': 'actual'})
            predictions[f'Chronos-{size}'] = chronos_df
            print(f"   âœ… {len(chronos_df)}ä»¶")
        else:
            print(f"   âš ï¸ {filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    # Chronos-Boltï¼ˆå…¨ã‚µã‚¤ã‚ºï¼‰
    for size in BOLT_SIZES:
        filename = f"chronos_bolt_predictions_{size}.csv"
        print(f"ğŸ“‚ Bolt-{size}äºˆæ¸¬ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        if os.path.exists(filename):
            bolt_df = pd.read_csv(filename)
            bolt_df['date'] = pd.to_datetime(bolt_df['date'])
            bolt_df = bolt_df.rename(columns={'sales': 'actual'})
            predictions[f'Bolt-{size}'] = bolt_df
            print(f"   âœ… {len(bolt_df)}ä»¶")
        else:
            print(f"   âš ï¸ {filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    return predictions


def calculate_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict[str, float]:
    """è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—"""
    return {
        'RMSE': root_mean_squared_error(y_true, y_pred),
        'MAE': mean_absolute_error(y_true, y_pred),
        'MAPE': mean_absolute_percentage_error(y_true, y_pred),
        'R2': r2_score(y_true, y_pred)
    }


def compare_all_models(predictions: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """å…¨ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ"""
    print("\n" + "=" * 60)
    print("ğŸ“Š å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ")
    print("=" * 60)

    results = []

    for model_name, df in predictions.items():
        metrics = calculate_metrics(df['actual'], df['prediction'])
        metrics['model'] = model_name
        results.append(metrics)

        print(f"\nã€{model_name}ã€‘")
        print(f"   RMSE: Â¥{metrics['RMSE']:,.0f}")
        print(f"   MAE:  Â¥{metrics['MAE']:,.0f}")
        print(f"   MAPE: {metrics['MAPE']:.2f}%")
        print(f"   RÂ²:   {metrics['R2']:.4f}")

    results_df = pd.DataFrame(results)
    results_df = results_df[['model', 'RMSE', 'MAE', 'MAPE', 'R2']]

    return results_df


def plot_all_models_comparison(
    predictions: dict[str, pd.DataFrame],
    metrics_df: pd.DataFrame,
    save_path: str = "figures/"
) -> None:
    """å…¨ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒçµæœã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
    os.makedirs(save_path, exist_ok=True)

    # === 1. äºˆæ¸¬çµæœã®æ™‚ç³»åˆ—æ¯”è¼ƒ ===
    fig, ax = plt.subplots(figsize=(16, 8))

    # å®Ÿç¸¾
    first_df = list(predictions.values())[0]
    ax.plot(first_df['date'], first_df['actual'],
            label='å®Ÿç¸¾', linewidth=2.5, color='black', marker='o', markersize=2)

    # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬
    for model_name, df in predictions.items():
        ax.plot(df['date'], df['prediction'],
                label=f'{model_name}',
                linewidth=1.5, linestyle='--',
                color=MODEL_COLORS.get(model_name, 'gray'))

    ax.set_title('å®Ÿç¸¾ vs å…¨ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬æ¯”è¼ƒ', fontsize=14, fontweight='bold')
    ax.set_xlabel('æ—¥ä»˜')
    ax.set_ylabel('å£²ä¸Šï¼ˆå††ï¼‰')
    ax.legend(loc='upper left', fontsize=8, ncol=2)
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(f"{save_path}15_all_models_timeseries.png", dpi=150, bbox_inches='tight')
    plt.close()

    # === 2. è©•ä¾¡æŒ‡æ¨™ã®æ¯”è¼ƒï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰ ===
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    metrics_list = ['RMSE', 'MAE', 'MAPE', 'R2']
    bar_colors = [MODEL_COLORS.get(m, 'gray') for m in metrics_df['model']]

    for idx, metric in enumerate(metrics_list):
        ax = axes[idx // 2, idx % 2]
        values = metrics_df[metric].values
        models = metrics_df['model'].values

        bars = ax.bar(range(len(models)), values, color=bar_colors)
        ax.set_title(f'{metric}', fontsize=14, fontweight='bold')
        ax.set_xticks(range(len(models)))
        ax.set_xticklabels(models, rotation=60, ha='right', fontsize=8)

        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, val in zip(bars, values):
            if metric in ['RMSE', 'MAE']:
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                        f'Â¥{val:,.0f}', ha='center', va='bottom', fontsize=7, rotation=45)
            elif metric == 'MAPE':
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                        f'{val:.1f}%', ha='center', va='bottom', fontsize=7, rotation=45)
            else:
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                        f'{val:.3f}', ha='center', va='bottom', fontsize=7, rotation=45)

        if metric == 'R2':
            ax.set_ylabel('ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰')
        else:
            ax.set_ylabel('èª¤å·®ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰')

    plt.tight_layout()
    plt.savefig(f"{save_path}16_all_models_metrics.png", dpi=150, bbox_inches='tight')
    plt.close()

    # === 3. RÂ²ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚° ===
    fig, ax = plt.subplots(figsize=(12, 8))

    sorted_df = metrics_df.sort_values('R2', ascending=True)
    colors = [MODEL_COLORS.get(m, 'gray') for m in sorted_df['model']]

    bars = ax.barh(sorted_df['model'], sorted_df['R2'], color=colors)

    # å€¤ã‚’è¡¨ç¤º
    for bar, val in zip(bars, sorted_df['R2']):
        ax.text(val + 0.001, bar.get_y() + bar.get_height()/2,
                f'{val:.4f}', va='center', fontsize=9)

    ax.set_xlabel('RÂ²ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰')
    ax.set_title('ãƒ¢ãƒ‡ãƒ«åˆ¥ RÂ²ã‚¹ã‚³ã‚¢ ãƒ©ãƒ³ã‚­ãƒ³ã‚°', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='x')

    plt.tight_layout()
    plt.savefig(f"{save_path}17_r2_ranking.png", dpi=150, bbox_inches='tight')
    plt.close()

    # === 4. æ®‹å·®åˆ†æï¼ˆä¸Šä½3ãƒ¢ãƒ‡ãƒ«ï¼‰ ===
    top3 = metrics_df.nlargest(3, 'R2')['model'].tolist()

    fig, axes = plt.subplots(1, 3, figsize=(16, 5))

    for idx, model_name in enumerate(top3):
        ax = axes[idx]
        df = predictions[model_name]
        residuals = df['actual'] - df['prediction']

        ax.scatter(df['prediction'], residuals, alpha=0.6,
                   color=MODEL_COLORS.get(model_name, 'gray'), s=30)
        ax.axhline(y=0, color='red', linestyle='--', linewidth=2)
        ax.set_title(f'{model_name} æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ', fontsize=12, fontweight='bold')
        ax.set_xlabel('äºˆæ¸¬å€¤')
        ax.set_ylabel('æ®‹å·®ï¼ˆå®Ÿç¸¾ - äºˆæ¸¬ï¼‰')
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(f"{save_path}18_top3_residuals.png", dpi=150, bbox_inches='tight')
    plt.close()

    # === 5. èª¤å·®åˆ†å¸ƒï¼ˆä¸Šä½3ãƒ¢ãƒ‡ãƒ«ï¼‰ ===
    fig, axes = plt.subplots(1, 3, figsize=(16, 5))

    for idx, model_name in enumerate(top3):
        ax = axes[idx]
        df = predictions[model_name]
        errors = df['actual'] - df['prediction']

        ax.hist(errors, bins=30, edgecolor='white', alpha=0.7,
                color=MODEL_COLORS.get(model_name, 'gray'))
        ax.axvline(x=0, color='red', linestyle='--', linewidth=2)
        ax.axvline(x=errors.mean(), color='orange', linestyle='--', linewidth=2,
                   label=f'å¹³å‡èª¤å·®: Â¥{errors.mean():,.0f}')
        ax.set_title(f'{model_name} èª¤å·®ã®åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        ax.set_xlabel('èª¤å·®ï¼ˆå®Ÿç¸¾ - äºˆæ¸¬ï¼‰')
        ax.set_ylabel('é »åº¦')
        ax.legend()

    plt.tight_layout()
    plt.savefig(f"{save_path}19_top3_error_dist.png", dpi=150, bbox_inches='tight')
    plt.close()

    # === 6. ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥æ¯”è¼ƒ ===
    fig, ax = plt.subplots(figsize=(12, 6))

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
    type_models = []
    type_labels = []

    if 'Prophet' in predictions:
        type_models.append('Prophet')
        type_labels.append('Prophet')

    if 'LightGBM' in predictions:
        type_models.append('LightGBM')
        type_labels.append('LightGBM')

    # Chronosãƒ™ã‚¹ãƒˆ
    chronos_models = [m for m in metrics_df['model'] if m.startswith('Chronos-')]
    if chronos_models:
        best_chronos = metrics_df[metrics_df['model'].isin(chronos_models)].nlargest(1, 'R2')['model'].iloc[0]
        type_models.append(best_chronos)
        type_labels.append(f'Chronos\n({best_chronos.split("-")[1]})')

    # Boltãƒ™ã‚¹ãƒˆ
    bolt_models = [m for m in metrics_df['model'] if m.startswith('Bolt-')]
    if bolt_models:
        best_bolt = metrics_df[metrics_df['model'].isin(bolt_models)].nlargest(1, 'R2')['model'].iloc[0]
        type_models.append(best_bolt)
        type_labels.append(f'Bolt\n({best_bolt.split("-")[1]})')

    if type_models:
        type_df = metrics_df[metrics_df['model'].isin(type_models)]
        x = np.arange(len(type_models))

        colors = [MODEL_COLORS.get(m, 'gray') for m in type_models]
        r2_values = [type_df[type_df['model'] == m]['R2'].values[0] for m in type_models]

        bars = ax.bar(x, r2_values, color=colors)

        for bar, val in zip(bars, r2_values):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                    f'{val:.4f}', ha='center', va='bottom', fontsize=10)

        ax.set_ylabel('RÂ²ã‚¹ã‚³ã‚¢')
        ax.set_title('ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥ ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(type_labels)
        ax.grid(True, alpha=0.3, axis='y')

        plt.tight_layout()
        plt.savefig(f"{save_path}20_model_type_comparison.png", dpi=150, bbox_inches='tight')
        plt.close()

    # === 7. Chronos vs Bolt æ¯”è¼ƒ ===
    if chronos_models and bolt_models:
        fig, ax = plt.subplots(figsize=(14, 6))

        chronos_df = metrics_df[metrics_df['model'].isin(chronos_models)].sort_values('model')
        bolt_df = metrics_df[metrics_df['model'].isin(bolt_models)].sort_values('model')

        x = np.arange(max(len(chronos_df), len(bolt_df)))
        width = 0.35

        # Chronos
        chronos_r2 = chronos_df['R2'].values
        ax.bar(x[:len(chronos_r2)] - width/2, chronos_r2, width,
               label='Chronos', color='#3498db')

        # Bolt
        bolt_r2 = bolt_df['R2'].values
        ax.bar(x[:len(bolt_r2)] + width/2, bolt_r2, width,
               label='Bolt', color='#e74c3c')

        ax.set_ylabel('RÂ²ã‚¹ã‚³ã‚¢')
        ax.set_title('Chronos vs Chronos-Bolt ã‚µã‚¤ã‚ºåˆ¥æ¯”è¼ƒ', fontsize=14, fontweight='bold')
        ax.set_xticks(x[:max(len(chronos_df), len(bolt_df))])
        labels = ['tiny', 'small/mini', 'base', 'large'][:max(len(chronos_df), len(bolt_df))]
        ax.set_xticklabels(labels)
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')

        plt.tight_layout()
        plt.savefig(f"{save_path}21_chronos_vs_bolt.png", dpi=150, bbox_inches='tight')
        plt.close()

    print(f"\nâœ… æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆ15ã€œ21ï¼‰")


def winner_summary(metrics_df: pd.DataFrame) -> None:
    """å‹è€…ã‚’ç™ºè¡¨"""
    print("\n" + "=" * 60)
    print("ğŸ† å…¨ãƒ¢ãƒ‡ãƒ«ç·åˆè©•ä¾¡")
    print("=" * 60)

    # è©•ä¾¡çµæœãƒ†ãƒ¼ãƒ–ãƒ«
    print("\nğŸ“Š è©•ä¾¡çµæœä¸€è¦§:")
    print(metrics_df.to_string(index=False))

    # å„æŒ‡æ¨™ã§ã®å‹è€…
    print("\nå„æŒ‡æ¨™ã§ã®ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«:")

    for metric in ['RMSE', 'MAE', 'MAPE']:
        best_idx = metrics_df[metric].idxmin()
        best_model = metrics_df.loc[best_idx, 'model']
        best_value = metrics_df.loc[best_idx, metric]
        if metric in ['RMSE', 'MAE']:
            print(f"   {metric}: {best_model} (Â¥{best_value:,.0f})")
        else:
            print(f"   {metric}: {best_model} ({best_value:.2f}%)")

    best_idx = metrics_df['R2'].idxmax()
    best_model = metrics_df.loc[best_idx, 'model']
    best_value = metrics_df.loc[best_idx, 'R2']
    print(f"   RÂ²: {best_model} ({best_value:.4f})")

    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    print("\nğŸ“Š RÂ²ã‚¹ã‚³ã‚¢ ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
    ranking = metrics_df.sort_values('R2', ascending=False)
    medals = ['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰'] + [f'{i}.' for i in range(4, 20)]
    for i, row in enumerate(ranking.itertuples()):
        medal = medals[i] if i < len(medals) else f'{i+1}.'
        print(f"   {medal} {row.model}: RÂ²={row.R2:.4f}, MAPE={row.MAPE:.2f}%")

    # ç·åˆå‹è€…
    overall_best = metrics_df.loc[metrics_df['R2'].idxmax(), 'model']
    print(f"\nğŸ‰ ç·åˆ1ä½: ã€{overall_best}ã€‘")

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ™ã‚¹ãƒˆ
    print("\n" + "-" * 40)
    print("ğŸ“ ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ™ã‚¹ãƒˆ:")
    print("-" * 40)

    # å¾“æ¥æ‰‹æ³•ãƒ™ã‚¹ãƒˆ
    traditional = metrics_df[metrics_df['model'].isin(['Prophet', 'LightGBM'])]
    if len(traditional) > 0:
        best_trad = traditional.loc[traditional['R2'].idxmax(), 'model']
        print(f"   å¾“æ¥æ‰‹æ³•ãƒ™ã‚¹ãƒˆ: {best_trad}")

    # Chronosãƒ™ã‚¹ãƒˆ
    chronos = metrics_df[metrics_df['model'].str.startswith('Chronos-')]
    if len(chronos) > 0:
        best_chronos = chronos.loc[chronos['R2'].idxmax(), 'model']
        print(f"   Chronosãƒ™ã‚¹ãƒˆ: {best_chronos}")

    # Boltãƒ™ã‚¹ãƒˆ
    bolt = metrics_df[metrics_df['model'].str.startswith('Bolt-')]
    if len(bolt) > 0:
        best_bolt = bolt.loc[bolt['R2'].idxmax(), 'model']
        print(f"   Boltãƒ™ã‚¹ãƒˆ: {best_bolt}")

    # å„ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´
    print("\n" + "-" * 40)
    print("ğŸ“ å„ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´:")
    print("-" * 40)
    print("""
ã€Prophetã€‘
  - å¼·ã¿: æˆåˆ†åˆ†è§£ã€è§£é‡ˆæ€§ã€ã‚¤ãƒ™ãƒ³ãƒˆåŠ¹æœ
  - å‘ã„ã¦ã„ã‚‹å ´é¢: ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒãƒ¼ãƒˆã€é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰

ã€LightGBMã€‘
  - å¼·ã¿: é«˜ç²¾åº¦ã€å¤šå¤‰é‡å¯¾å¿œã€é«˜é€Ÿ
  - å‘ã„ã¦ã„ã‚‹å ´é¢: çŸ­æœŸäºˆæ¸¬ã€ç‰¹å¾´é‡ãŒè±Šå¯Œãªãƒ‡ãƒ¼ã‚¿

ã€Chronosï¼ˆå¾“æ¥ç‰ˆï¼‰ã€‘
  - tiny/small/base/large ã®4ã‚µã‚¤ã‚º
  - å¼·ã¿: ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã€é«˜ç²¾åº¦
  - å¼±ã¿: æ¨è«–é€Ÿåº¦ãŒã‚„ã‚„é…ã„

ã€Chronos-Boltï¼ˆé«˜é€Ÿç‰ˆï¼‰ã€‘
  - tiny/mini/small/base ã®4ã‚µã‚¤ã‚º
  - å¼·ã¿: å¾“æ¥æ¯”æœ€å¤§250å€é«˜é€Ÿã€åˆ†ä½ç‚¹ç›´æ¥å‡ºåŠ›
  - å‘ã„ã¦ã„ã‚‹å ´é¢: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ã€å¤§é‡ãƒãƒƒãƒå‡¦ç†
""")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ”¬ å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ")
    print("   Prophet / LightGBM / Chronos / Chronos-Bolt")
    print("=" * 60)

    # äºˆæ¸¬çµæœã‚’èª­ã¿è¾¼ã¿
    predictions = load_all_predictions()

    if len(predictions) == 0:
        print("âŒ äºˆæ¸¬çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å„ãƒ¢ãƒ‡ãƒ«ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None

    # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
    metrics_df = compare_all_models(predictions)

    # æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ
    plot_all_models_comparison(predictions, metrics_df)

    # ç·åˆè©•ä¾¡
    winner_summary(metrics_df)

    # çµæœã‚’ä¿å­˜
    metrics_df.to_csv("all_models_comparison.csv", index=False)
    print("\nâœ… æ¯”è¼ƒçµæœã‚’ all_models_comparison.csv ã«ä¿å­˜ã—ã¾ã—ãŸ")

    return metrics_df


if __name__ == "__main__":
    metrics_df = main()
